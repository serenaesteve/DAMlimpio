Para practicar el análisis de sentimiento y mejorar tus habilidades técnicas en este campo, sigue estos pasos:

Revisión de conceptos: Comienza revisando los conceptos clave que hemos aprendido en esta unidad sobre analisis de sentimiento, como accuracy, listas de palabras positivas y negativas, y métricas habituales.

Práctica con ejemplos: Utiliza las herramientas de TextBlob o cualquier otra biblioteca de NLP para practicar el análisis de sentimientos en diversos textos. Crea una lista de frases positivas y negativas y clasificalas usando tu propio criterio. Luego, compara tus resultados con los obtenidos por un sistema basado en reglas.

Análisis de errores: Identifica los posibles errores comunes como el sarcasmo o la ambigüedad de términos y crea ejemplos que demuestren cómo estos pueden afectar las predicciones del análisis de sentimiento.

Evaluación cruzada: Realiza pruebas exhaustivas en un conjunto diverso de textos para validar la precisión de tu sistema. Ajusta tus listas de palabras positivas y negativas según los resultados obtenidos.

Monitoreo y actualización regular: Monitorea el rendimiento de tu sistema y actualiza regularmente las listas de palabras según los cambios en el lenguaje y las preferencias del público.

Siguiendo estos pasos, podrás mejorar tus habilidades técnicas en análisis de sentimiento y aplicarlos con confianza en diversos contextos. ¡Buena suerte!



Respuesta:



En este trabajo realizo un ejercicio de análisis de sentimiento con el objetivo de aprender cómo se puede analizar un texto y determinar si su contenido es positivo, negativo o neutral. El ejercicio me ayuda a entender cómo funcionan estos sistemas y qué problemas pueden aparecer al analizar el lenguaje natural.

Terminal:
```
serena@serena-portatil:~$ pip install textblob scikit-learn pandas
python -m textblob.download_corpora
error: externally-managed-environment

× This environment is externally managed
╰─> To install Python packages system-wide, try apt install
    python3-xyz, where xyz is the package you are trying to
    install.
    
    If you wish to install a non-Debian-packaged Python package,
    create a virtual environment using python3 -m venv path/to/venv.
    Then use path/to/venv/bin/python and path/to/venv/bin/pip. Make
    sure you have python3-full installed.
    
    If you wish to install a non-Debian packaged Python application,
    it may be easiest to use pipx install xyz, which will manage a
    virtual environment for you. Make sure you have pipx installed.
    
    See /usr/share/doc/python3.12/README.venv for more information.

note: If you believe this is a mistake, please contact your Python installation or OS distribution provider. You can override this, at the risk of breaking your Python installation or OS, by passing --break-system-packages.
hint: See PEP 668 for the detailed specification.
Orden «python» no encontrada. Quizá quiso decir:
  la orden «python3» del paquete deb «python3»
  la orden «python» del paquete deb «python-is-python3»
serena@serena-portatil:~$ sudo apt update
sudo apt install python3-full python3-venv -y
[sudo] contraseña para serena: 
Obj:1 http://es.archive.ubuntu.com/ubuntu noble InRelease
Des:2 http://security.ubuntu.com/ubuntu noble-security InRelease [126 kB]      
Des:3 http://es.archive.ubuntu.com/ubuntu noble-updates InRelease [126 kB]     
Ign:4 https://apt.packages.shiftkey.dev/ubuntu any InRelease                   
Obj:5 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu noble InRelease   
Des:6 http://es.archive.ubuntu.com/ubuntu noble-backports InRelease [126 kB]   
Des:7 http://security.ubuntu.com/ubuntu noble-security/main amd64 Packages [1.446 kB]
Des:8 http://es.archive.ubuntu.com/ubuntu noble-updates/main amd64 Packages [1.740 kB]
Ign:4 https://apt.packages.shiftkey.dev/ubuntu any InRelease        
Des:9 http://security.ubuntu.com/ubuntu noble-security/main Translation-en [234 kB]
Des:10 http://security.ubuntu.com/ubuntu noble-security/main amd64 Components [21,5 kB]
Des:11 http://security.ubuntu.com/ubuntu noble-security/main amd64 c-n-f Metadata [9.892 B]
Des:12 http://security.ubuntu.com/ubuntu noble-security/restricted amd64 Packages [2.445 kB]
Ign:4 https://apt.packages.shiftkey.dev/ubuntu any InRelease                   
Des:13 http://es.archive.ubuntu.com/ubuntu noble-updates/main Translation-en [324 kB]
Des:14 http://es.archive.ubuntu.com/ubuntu noble-updates/main amd64 Components [175 kB]
Des:15 http://es.archive.ubuntu.com/ubuntu noble-updates/main amd64 c-n-f Metadata [16,5 kB]
Des:16 http://es.archive.ubuntu.com/ubuntu noble-updates/restricted amd64 Packages [2.588 kB]
Des:17 http://security.ubuntu.com/ubuntu noble-security/restricted Translation-en [562 kB]
Des:18 http://security.ubuntu.com/ubuntu noble-security/restricted amd64 Components [212 B]
Des:19 http://security.ubuntu.com/ubuntu noble-security/universe amd64 Packages [929 kB]
Des:20 http://security.ubuntu.com/ubuntu noble-security/universe amd64 Components [74,2 kB]
Des:21 http://security.ubuntu.com/ubuntu noble-security/multiverse amd64 Components [208 B]
Des:22 http://es.archive.ubuntu.com/ubuntu noble-updates/restricted Translation-en [593 kB]
Err:4 https://apt.packages.shiftkey.dev/ubuntu any InRelease                   
  Certificate verification failed: The certificate is NOT trusted. The name in the certificate does not match the expected.  Could not handshake: Error in the certificate verification. [IP: 13.107.213.43 443]
Des:23 http://es.archive.ubuntu.com/ubuntu noble-updates/restricted amd64 Components [212 B]
Des:24 http://es.archive.ubuntu.com/ubuntu noble-updates/universe amd64 Packages [1.528 kB]
Des:25 http://es.archive.ubuntu.com/ubuntu noble-updates/universe Translation-en [313 kB]
Des:26 http://es.archive.ubuntu.com/ubuntu noble-updates/universe amd64 Components [386 kB]
Des:27 http://es.archive.ubuntu.com/ubuntu noble-updates/multiverse amd64 Components [940 B]
Des:28 http://es.archive.ubuntu.com/ubuntu noble-backports/main amd64 Components [7.300 B]
Des:29 http://es.archive.ubuntu.com/ubuntu noble-backports/restricted amd64 Components [212 B]
Des:30 http://es.archive.ubuntu.com/ubuntu noble-backports/universe amd64 Components [10,5 kB]
Des:31 http://es.archive.ubuntu.com/ubuntu noble-backports/multiverse amd64 Components [212 B]
Descargados 13,8 MB en 10s (1.340 kB/s)                                        
Leyendo lista de paquetes... Hecho
Creando árbol de dependencias... Hecho
Leyendo la información de estado... Hecho
Se pueden actualizar 182 paquetes. Ejecute «apt list --upgradable» para verlos.
W: Fallo al obtener https://apt.packages.shiftkey.dev/ubuntu/dists/any/InRelease  Certificate verification failed: The certificate is NOT trusted. The name in the certificate does not match the expected.  Could not handshake: Error in the certificate verification. [IP: 13.107.213.43 443]
W: No se han podido descargar algunos archivos de índice, se han omitido, o se han utilizado unos antiguos en su lugar.
Leyendo lista de paquetes... Hecho
Creando árbol de dependencias... Hecho
Leyendo la información de estado... Hecho
python3-full ya está en su versión más reciente (3.12.3-0ubuntu2.1).
python3-venv ya está en su versión más reciente (3.12.3-0ubuntu2.1).
El paquete indicado a continuación se instaló de forma automática y ya no es necesario.
  libllvm19
Utilice «sudo apt autoremove» para eliminarlo.
0 actualizados, 0 nuevos se instalarán, 0 para eliminar y 182 no actualizados.
serena@serena-portatil:~$ python3 -m venv nlp_env
serena@serena-portatil:~$ source nlp_env/bin/activate
(nlp_env) serena@serena-portatil:~$ pip install textblob scikit-learn pandas
Collecting textblob
  Downloading textblob-0.19.0-py3-none-any.whl.metadata (4.4 kB)
Collecting scikit-learn
  Downloading scikit_learn-1.8.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (11 kB)
Collecting pandas
  Downloading pandas-3.0.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (79 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 79.5/79.5 kB 221.1 kB/s eta 0:00:00
Collecting nltk>=3.9 (from textblob)
  Downloading nltk-3.9.2-py3-none-any.whl.metadata (3.2 kB)
Collecting numpy>=1.24.1 (from scikit-learn)
  Using cached numpy-2.4.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (6.6 kB)
Collecting scipy>=1.10.0 (from scikit-learn)
  Using cached scipy-1.17.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (62 kB)
Collecting joblib>=1.3.0 (from scikit-learn)
  Downloading joblib-1.5.3-py3-none-any.whl.metadata (5.5 kB)
Collecting threadpoolctl>=3.2.0 (from scikit-learn)
  Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)
Collecting python-dateutil>=2.8.2 (from pandas)
  Using cached python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)
Collecting click (from nltk>=3.9->textblob)
  Using cached click-8.3.1-py3-none-any.whl.metadata (2.6 kB)
Collecting regex>=2021.8.3 (from nltk>=3.9->textblob)
  Using cached regex-2026.1.15-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (40 kB)
Collecting tqdm (from nltk>=3.9->textblob)
  Downloading tqdm-4.67.3-py3-none-any.whl.metadata (57 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 57.7/57.7 kB 1.2 MB/s eta 0:00:00
Collecting six>=1.5 (from python-dateutil>=2.8.2->pandas)
  Using cached six-1.17.0-py2.py3-none-any.whl.metadata (1.7 kB)
Downloading textblob-0.19.0-py3-none-any.whl (624 kB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 624.3/624.3 kB 321.7 kB/s eta 0:00:00
Downloading scikit_learn-1.8.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (8.9 MB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 8.9/8.9 MB 1.6 MB/s eta 0:00:00
Downloading pandas-3.0.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (10.9 MB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 10.9/10.9 MB 1.6 MB/s eta 0:00:00
Downloading joblib-1.5.3-py3-none-any.whl (309 kB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 309.1/309.1 kB 515.1 kB/s eta 0:00:00
Downloading nltk-3.9.2-py3-none-any.whl (1.5 MB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.5/1.5 MB 1.6 MB/s eta 0:00:00
Using cached numpy-2.4.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.6 MB)
Using cached python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)
Downloading scipy-1.17.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (35.0 MB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 35.0/35.0 MB 1.8 MB/s eta 0:00:00
Downloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)
Using cached regex-2026.1.15-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (803 kB)
Using cached six-1.17.0-py2.py3-none-any.whl (11 kB)
Using cached click-8.3.1-py3-none-any.whl (108 kB)
Downloading tqdm-4.67.3-py3-none-any.whl (78 kB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 78.4/78.4 kB 7.4 MB/s eta 0:00:00
Installing collected packages: tqdm, threadpoolctl, six, regex, numpy, joblib, click, scipy, python-dateutil, nltk, textblob, scikit-learn, pandas
Successfully installed click-8.3.1 joblib-1.5.3 nltk-3.9.2 numpy-2.4.2 pandas-3.0.0 python-dateutil-2.9.0.post0 regex-2026.1.15 scikit-learn-1.8.0 scipy-1.17.0 six-1.17.0 textblob-0.19.0 threadpoolctl-3.6.0 tqdm-4.67.3
(nlp_env) serena@serena-portatil:~$ python -m textblob.download_corpora
[nltk_data] Downloading package brown to /home/serena/nltk_data...
[nltk_data]   Unzipping corpora/brown.zip.
[nltk_data] Downloading package punkt_tab to /home/serena/nltk_data...
[nltk_data]   Unzipping tokenizers/punkt_tab.zip.
[nltk_data] Downloading package wordnet to /home/serena/nltk_data...
[nltk_data] Downloading package averaged_perceptron_tagger_eng to
[nltk_data]     /home/serena/nltk_data...
[nltk_data]   Unzipping taggers/averaged_perceptron_tagger_eng.zip.
[nltk_data] Downloading package conll2000 to /home/serena/nltk_data...
[nltk_data]   Unzipping corpora/conll2000.zip.
[nltk_data] Downloading package movie_reviews to
[nltk_data]     /home/serena/nltk_data...
[nltk_data]   Unzipping corpora/movie_reviews.zip.
Finished.
(nlp_env) serena@serena-portatil:~$ python
Python 3.12.3 (main, Jan 22 2026, 20:57:42) [GCC 13.3.0] on linux
Type "help", "copyright", "credits" or "license" for more information.
>>> from textblob import TextBlob
>>> TextBlob("Me encanta este curso").sentiment
Sentiment(polarity=0.0, subjectivity=0.0)
>>> data = [
...     ("Me encanta este servicio, es excelente", "pos"),
...     ("Es horrible, no lo recomiendo", "neg"),
...     ("Está bien, sin más", "neu"),
...     ("Genial… otra vez llegó tarde", "neg"),  # sarcasmo
...     ("No es malo", "pos"),                    # negación
... ]
>>> def textblob_sentimiento(texto):
...     p = TextBlob(texto).sentiment.polarity
...     if p > 0.1:
...         return "pos"
...     if p < -0.1:
...         return "neg"
...     return "neu"
... 
>>> y_real = [y for _, y in data]
>>> y_pred = [textblob_sentimiento(x) for x, _ in data]
>>> 
>>> list(zip([x for x, _ in data], y_real, y_pred))
[('Me encanta este servicio, es excelente', 'pos', 'neu'), ('Es horrible, no lo recomiendo', 'neg', 'neg'), ('Está bien, sin más', 'neu', 'neu'), ('Genial… otra vez llegó tarde', 'neg', 'neu'), ('No es malo', 'pos', 'neu')]
>>> 
>>> from sklearn.metrics import accuracy_score, classification_report
>>> 
>>> print("Accuracy:", accuracy_score(y_real, y_pred))
Accuracy: 0.4
>>> print(classification_report(y_real, y_pred))
/home/serena/nlp_env/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1833: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/serena/nlp_env/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1833: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/serena/nlp_env/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1833: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
              precision    recall  f1-score   support

         neg       1.00      0.50      0.67         2
         neu       0.25      1.00      0.40         1
         pos       0.00      0.00      0.00         2

    accuracy                           0.40         5
   macro avg       0.42      0.50      0.36         5
weighted avg       0.45      0.40      0.35         5

>>> for (x, y), pred in zip(data, y_pred):
...     if y != pred:
...         print("TEXTO:", x)
...         print("REAL:", y, "PRED:", pred)
...         print("----")
... 
TEXTO: Me encanta este servicio, es excelente
REAL: pos PRED: neu
----
TEXTO: Genial… otra vez llegó tarde
REAL: neg PRED: neu
----
TEXTO: No es malo
REAL: pos PRED: neu
----
>>> positivas = {"encanta", "excelente", "genial", "increíble", "perfecto", "maravilloso", "recomiendo"}
>>> negativas = {"horrible", "terrible", "pésimo", "malo", "tarde", "frustrante", "decepcionante"}
>>> import re
>>> 
>>> def reglas_sentimiento(texto):
...     t = texto.lower()
...     tokens = re.findall(r"\w+", t)
... 
>>>     score = 0
  File "<stdin>", line 1
    score = 0
IndentationError: unexpected indent
>>>     for w in tokens:
  File "<stdin>", line 1
    for w in tokens:
IndentationError: unexpected indent
>>>         if w in positivas:
  File "<stdin>", line 1
    if w in positivas:
IndentationError: unexpected indent
>>>             score += 1
  File "<stdin>", line 1
    score += 1
IndentationError: unexpected indent
>>>         if w in negativas:
  File "<stdin>", line 1
    if w in negativas:
IndentationError: unexpected indent
>>>             score -= 1
  File "<stdin>", line 1
    score -= 1
IndentationError: unexpected indent
>>> 
>>>     if score > 0:
  File "<stdin>", line 1
    if score > 0:
IndentationError: unexpected indent
>>>         return "pos"
  File "<stdin>", line 1
    return "pos"
IndentationError: unexpected indent
>>>     if score < 0:
  File "<stdin>", line 1
    if score < 0:
IndentationError: unexpected indent
>>>         return "neg"
  File "<stdin>", line 1
    return "neg"
IndentationError: unexpected indent
>>>     return "neu"
  File "<stdin>", line 1
    return "neu"
IndentationError: unexpected indent
>>> y_reglas = [reglas_sentimiento(x) for x, _ in data]
>>> list(zip([x for x, _ in data], y_real, y_reglas))
[('Me encanta este servicio, es excelente', 'pos', None), ('Es horrible, no lo recomiendo', 'neg', None), ('Está bien, sin más', 'neu', None), ('Genial… otra vez llegó tarde', 'neg', None), ('No es malo', 'pos', None)]
>>> from sklearn.metrics import accuracy_score, classification_report
>>> 
>>> print("Accuracy (reglas):", accuracy_score(y_real, y_reglas))
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
  File "/home/serena/nlp_env/lib/python3.12/site-packages/sklearn/utils/_param_validation.py", line 218, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/serena/nlp_env/lib/python3.12/site-packages/sklearn/metrics/_classification.py", line 411, in accuracy_score
    y_type, y_true, y_pred, sample_weight = _check_targets(
                                            ^^^^^^^^^^^^^^^
  File "/home/serena/nlp_env/lib/python3.12/site-packages/sklearn/metrics/_classification.py", line 127, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of multiclass and unknown targets
>>> print(classification_report(y_real, y_reglas, zero_division=0))
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
  File "/home/serena/nlp_env/lib/python3.12/site-packages/sklearn/utils/_param_validation.py", line 218, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/serena/nlp_env/lib/python3.12/site-packages/sklearn/metrics/_classification.py", line 3073, in classification_report
    y_type, y_true, y_pred, sample_weight = _check_targets(
                                            ^^^^^^^^^^^^^^^
  File "/home/serena/nlp_env/lib/python3.12/site-packages/sklearn/metrics/_classification.py", line 127, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of multiclass and unknown targets
>>> for (x, y), pred in zip(data, y_reglas):
...     if y != pred:
...         print("TEXTO:", x)
...         print("REAL:", y, "PRED:", pred)
...         print("----")
... exit()
  File "<stdin>", line 6
    exit()
    ^^^^
SyntaxError: invalid syntax
>>> exit()
(nlp_env) serena@serena-portatil:~$ python
Python 3.12.3 (main, Jan 22 2026, 20:57:42) [GCC 13.3.0] on linux
Type "help", "copyright", "credits" or "license" for more information.
>>> import re
>>> 
>>> positivas = {"encanta", "excelente", "genial", "increíble", "perfecto", "maravilloso", "recomiendo"}
>>> negativas = {"horrible", "terrible", "pésimo", "malo", "tarde", "frustrante", "decepcionante"}
>>> 
>>> def reglas_sentimiento(texto):
...     t = texto.lower()
...     tokens = re.findall(r"\w+", t)
... 
>>>     score = 0
  File "<stdin>", line 1
    score = 0
IndentationError: unexpected indent
>>>     for w in tokens:
  File "<stdin>", line 1
    for w in tokens:
IndentationError: unexpected indent
>>>         if w in positivas:
  File "<stdin>", line 1
    if w in positivas:
IndentationError: unexpected indent
>>>             score += 1
  File "<stdin>", line 1
    score += 1
IndentationError: unexpected indent
>>>         if w in negativas:
  File "<stdin>", line 1
    if w in negativas:
IndentationError: unexpected indent
>>>             score -= 1
  File "<stdin>", line 1
    score -= 1
IndentationError: unexpected indent
>>> 
>>>     if score > 0:
  File "<stdin>", line 1
    if score > 0:
IndentationError: unexpected indent
>>>         return "pos"
  File "<stdin>", line 1
    return "pos"
IndentationError: unexpected indent
>>>     if score < 0:
  File "<stdin>", line 1
    if score < 0:
IndentationError: unexpected indent
>>>         return "neg"
  File "<stdin>", line 1
    return "neg"
IndentationError: unexpected indent
>>>     return "neu"
  File "<stdin>", line 1
    return "neu"
IndentationError: unexpected indent
>>> y_reglas = [reglas_sentimiento(x) for x, _ in data]
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
NameError: name 'data' is not defined
>>> list(zip([x for x, _ in data], y_real, y_reglas))
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
NameError: name 'data' is not defined
>>> from sklearn.metrics import accuracy_score, classification_report
>>> 
>>> print("Accuracy (reglas):", accuracy_score(y_real, y_reglas))
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
NameError: name 'y_real' is not defined
>>> print(classification_report(y_real, y_reglas, zero_division=0))
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
NameError: name 'y_real' is not defined
>>> for (x, y), pred in zip(data, y_reglas):
...     if y != pred:
...         print("TEXTO:", x)
...         print("REAL:", y, "PRED:", pred)
...         print("----")
... 
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
NameError: name 'data' is not defined
>>> exit()
(nlp_env) serena@serena-portatil:~$ nano sentimiento.py
(nlp_env) serena@serena-portatil:~$ python sentimiento.py

=== TextBlob ===
[('Me encanta este servicio, es excelente', 'pos', 'neu'), ('Es horrible, no lo recomiendo', 'neg', 'neg'), ('Está bien, sin más', 'neu', 'neu'), ('Genial… otra vez llegó tarde', 'neg', 'neu'), ('No es malo', 'pos', 'neu')]
Accuracy: 0.4
              precision    recall  f1-score   support

         neg       1.00      0.50      0.67         2
         neu       0.25      1.00      0.40         1
         pos       0.00      0.00      0.00         2

    accuracy                           0.40         5
   macro avg       0.42      0.50      0.36         5
weighted avg       0.45      0.40      0.35         5


=== Reglas ===
[('Me encanta este servicio, es excelente', 'pos', 'pos'), ('Es horrible, no lo recomiendo', 'neg', 'neu'), ('Está bien, sin más', 'neu', 'neu'), ('Genial… otra vez llegó tarde', 'neg', 'neu'), ('No es malo', 'pos', 'neg')]
Accuracy: 0.4
              precision    recall  f1-score   support

         neg       0.00      0.00      0.00         2
         neu       0.33      1.00      0.50         1
         pos       1.00      0.50      0.67         2

    accuracy                           0.40         5
   macro avg       0.44      0.50      0.39         5
weighted avg       0.47      0.40      0.37         5


Errores (Reglas):
TEXTO: Es horrible, no lo recomiendo
REAL: neg PRED: neu
----
TEXTO: Genial… otra vez llegó tarde
REAL: neg PRED: neu
----
TEXTO: No es malo
REAL: pos PRED: neg
----
(nlp_env) serena@serena-portatil:~$ nano sentimiento.py
(nlp_env) serena@serena-portatil:~$ nano sentimiento.py
(nlp_env) serena@serena-portatil:~$ python sentimiento.py

=== TextBlob ===
[('Me encanta este servicio, es excelente', 'pos', 'neu'), ('Es horrible, no lo recomiendo', 'neg', 'neg'), ('Está bien, sin más', 'neu', 'neu'), ('Genial… otra vez llegó tarde', 'neg', 'neu'), ('No es malo', 'pos', 'neu')]
Accuracy: 0.4
              precision    recall  f1-score   support

         neg       1.00      0.50      0.67         2
         neu       0.25      1.00      0.40         1
         pos       0.00      0.00      0.00         2

    accuracy                           0.40         5
   macro avg       0.42      0.50      0.36         5
weighted avg       0.45      0.40      0.35         5


=== Reglas ===
[('Me encanta este servicio, es excelente', 'pos', 'pos'), ('Es horrible, no lo recomiendo', 'neg', 'neu'), ('Está bien, sin más', 'neu', 'neu'), ('Genial… otra vez llegó tarde', 'neg', 'neg'), ('No es malo', 'pos', 'neg')]
Accuracy: 0.6
              precision    recall  f1-score   support

         neg       0.50      0.50      0.50         2
         neu       0.50      1.00      0.67         1
         pos       1.00      0.50      0.67         2

    accuracy                           0.60         5
   macro avg       0.67      0.67      0.61         5
weighted avg       0.70      0.60      0.60         5


Errores (Reglas):
TEXTO: Es horrible, no lo recomiendo
REAL: neg PRED: neu
----
TEXTO: No es malo
REAL: pos PRED: neg
----
(nlp_env) serena@serena-portatil:~$ nano sentimiento.py
(nlp_env) serena@serena-portatil:~$ python sentimiento.py

=== TextBlob ===
[('Me encanta este servicio, es excelente', 'pos', 'neu'), ('Es horrible, no lo recomiendo', 'neg', 'neg'), ('Está bien, sin más', 'neu', 'neu'), ('Genial… otra vez llegó tarde', 'neg', 'neu'), ('No es malo', 'pos', 'neu')]
Accuracy: 0.4
              precision    recall  f1-score   support

         neg       1.00      0.50      0.67         2
         neu       0.25      1.00      0.40         1
         pos       0.00      0.00      0.00         2

    accuracy                           0.40         5
   macro avg       0.42      0.50      0.36         5
weighted avg       0.45      0.40      0.35         5


=== Reglas ===
[('Me encanta este servicio, es excelente', 'pos', 'pos'), ('Es horrible, no lo recomiendo', 'neg', 'neg'), ('Está bien, sin más', 'neu', 'neu'), ('Genial… otra vez llegó tarde', 'neg', 'neg'), ('No es malo', 'pos', 'pos')]
Accuracy: 1.0
              precision    recall  f1-score   support

         neg       1.00      1.00      1.00         2
         neu       1.00      1.00      1.00         1
         pos       1.00      1.00      1.00         2

    accuracy                           1.00         5
   macro avg       1.00      1.00      1.00         5
weighted avg       1.00      1.00      1.00         5


Errores (Reglas):
(nlp_env) serena@serena-portatil:~$ 
```



sentimiento.py:
```
import re
from textblob import TextBlob
from sklearn.metrics import accuracy_score, classification_report

# =========================
# 1) Dataset (verdad humana)
# =========================
data = [
    ("Me encanta este servicio, es excelente", "pos"),
    ("Es horrible, no lo recomiendo", "neg"),
    ("Está bien, sin más", "neu"),
    ("Genial… otra vez llegó tarde", "neg"),
    ("No es malo", "pos"),
]

y_real = [y for _, y in data]

# =========================
# 2) TextBlob (baseline)
# =========================
def textblob_sentimiento(texto):
    p = TextBlob(texto).sentiment.polarity
    if p > 0.1:
        return "pos"
    if p < -0.1:
        return "neg"
    return "neu"

y_blob = [textblob_sentimiento(x) for x, _ in data]

print("\n=== TextBlob ===")
print(list(zip([x for x, _ in data], y_real, y_blob)))
print("Accuracy:", accuracy_score(y_real, y_blob))
print(classification_report(y_real, y_blob, zero_division=0))

# =========================
# 3) Reglas mejoradas
# =========================
positivas = {
    "encanta", "excelente", "genial", "increíble",
    "perfecto", "maravilloso", "recomiendo"
}

negativas = {
    "horrible", "terrible", "pésimo", "malo",
    "tarde", "frustrante", "decepcionante"
}

negadores = {"no", "nunca", "jamás", "sin"}

def reglas_sentimiento(texto):
    t = texto.lower()
    tokens = re.findall(r"\w+", t)

    score = 0
    ventana_negacion = 3

    for i, w in enumerate(tokens):
        inicio = max(0, i - ventana_negacion)
        contexto = tokens[inicio:i]
        negado = any(tok in negadores for tok in contexto)

        if w in positivas:
            score += -1 if negado else 1
        elif w in negativas:
            score += 1 if negado else -1

    # Regla simple para quejas repetidas / sarcasmo básico
    if "otra" in tokens and "vez" in tokens:
        score -= 1

    if score > 0:
        return "pos"
    if score < 0:
        return "neg"
    return "neu"

y_reglas = [reglas_sentimiento(x) for x, _ in data]

print("\n=== Reglas ===")
print(list(zip([x for x, _ in data], y_real, y_reglas)))
print("Accuracy:", accuracy_score(y_real, y_reglas))
print(classification_report(y_real, y_reglas, zero_division=0))

print("\nErrores (Reglas):")
for (x, y), pred in zip(data, y_reglas):
    if y != pred:
        print("TEXTO:", x)
        print("REAL:", y, "PRED:", pred)
        print("----")
```

En este ejercicio trabajo el análisis de sentimiento para aprender a identificar si un texto es positivo, negativo o neutral. Primero preparo el entorno de trabajo e instalo las herramientas necesarias para poder usar Python sin problemas.

Después creo varias frases en español y las clasifico manualmente como positivas, negativas o neutrales. Estas frases me sirven como referencia para comprobar si el sistema acierta.

A continuación utilizo TextBlob para analizar el sentimiento de las frases y comparo los resultados con los valores reales. Veo que TextBlob no funciona bien en español, ya que muchas frases las clasifica como neutrales.

Luego creo mi propio sistema sencillo usando listas de palabras positivas y negativas. Pruebo este sistema y analizo los errores que comete, sobre todo en frases con negación y en frases que expresan queja o ironía.

Por último mejoro el sistema añadiendo reglas simples para tener en cuenta la negación y corregir esos errores. Con este ejercicio aprendo que el análisis de sentimiento necesita ajustes y que analizar los errores es importante para mejorar los resultados.


